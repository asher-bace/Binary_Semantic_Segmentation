import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
from models import unet  
from models import resnet34_unet
from oxford_pet import OxfordPets  
import utils
from utils import dice_score, iou_score  
import albumentations as A
from albumentations.pytorch import ToTensorV2
from glob import glob

# è¶…åƒæ•¸è¨­å®š #
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 8
IMG_SIZE = (256, 256)
NUM_CLASSES = 2  

# è¼‰å…¥æ¸¬è©¦é›† #
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATASET_PATH = os.path.join("dataset", "oxford-iiit-pet")
DATASET_PATH = os.path.join(BASE_DIR, DATASET_PATH)
IMAGE_PATH = os.path.join(DATASET_PATH, "images")
MASK_PATH = os.path.join(DATASET_PATH, "annotations", "trimaps")

test_img_files = sorted(glob(os.path.join(IMAGE_PATH, "*.jpg")))
test_mask_files = sorted(glob(os.path.join(MASK_PATH, "*.png")))

# è³‡æ–™è™•ç† #
transform = A.Compose([
    A.HorizontalFlip(p=0.5),                      # 50% æ©Ÿç‡æ°´å¹³ç¿»è½‰
    A.RandomRotate90(p=0.5),                      # éš¨æ©Ÿæ—‹è½‰ 90 åº¦
    A.Affine(                                     # éš¨æ©Ÿå¹³ç§»ã€ç¸®æ”¾ã€æ—‹è½‰
        scale=(0.9, 1.1), 
        translate_percent=(0.0, 0.1), 
        rotate=(-15, 15), p=0.5
        ),           
    A.RandomBrightnessContrast(p=0.3),            # éš¨æ©Ÿäº®åº¦å°æ¯”
    A.GaussianBlur(p=0.2),                        # æ¨¡ç³Šå½±åƒ
    A.Normalize(mean=(0.5, 0.5, 0.5),             # Normalize for image
                std=(0.5, 0.5, 0.5)),
    ToTensorV2()                                  # è½‰æˆ PyTorch Tensor
])


total_samples = len(test_img_files)
train_end = int(0.8 * total_samples)
val_end = int(0.9 * total_samples)  # å‰©ä¸‹çš„ 20% è£¡å†åˆ†ä¸€åŠçµ¦ val / test

test_img = test_img_files[val_end:]
test_mask = test_mask_files[val_end:]

test_dataset = OxfordPets(test_img, test_mask, transform=None)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

print(f"ğŸ§ª æ¸¬è©¦è³‡æ–™æ•¸é‡: {len(test_dataset)}")
print(f"ğŸ“¦ æ¸¬è©¦æ‰¹æ¬¡æ•¸é‡: {len(test_loader)}\n")

# è¼‰å…¥æ¨¡å‹ #
unet_model = unet.UNet(input_channels=3, num_classes=NUM_CLASSES).to(DEVICE)
resnet_model = resnet34_unet.ResNet34UNet(num_classes=NUM_CLASSES).to(DEVICE)

# âœ… ä¿®æ­£ `torch.load()`
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MODEL_DIR = os.path.join(BASE_DIR, "saved_models")
unet_path = os.path.join(MODEL_DIR, "best_unet_model.pth")
resnet_path = os.path.join(MODEL_DIR, "best_resnet34_unet_model.pth")

unet_path = os.path.join(MODEL_DIR, "best_unet_model.pth")
resnet_path = os.path.join(MODEL_DIR, "best_resnet34_unet_model.pth")
unet_model.load_state_dict(torch.load(unet_path, weights_only=True))
resnet_model.load_state_dict(torch.load(resnet_path, weights_only=True))
unet_model.eval()
resnet_model.eval()

# åŸ·è¡Œè©•ä¼°**
criterion = nn.CrossEntropyLoss()
utils.evaluate(unet_model, test_loader, criterion, DEVICE, "U-Net")
utils.evaluate(resnet_model, test_loader, criterion, DEVICE, "ResNet34 & U-Net")







