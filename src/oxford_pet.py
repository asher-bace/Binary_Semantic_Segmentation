import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
import albumentations as A
from albumentations.pytorch import ToTensorV2
import torch
from torch.utils.data import Dataset, DataLoader
import random
from sklearn.model_selection import train_test_split
import utils

class OxfordPets(Dataset):
    def __init__(self, input_image_paths, target_image_paths, image_size = (256, 256), transform = None):
        self.input_image_paths = input_image_paths
        self.target_image_paths = target_image_paths
        self.image_size = image_size
        self.transform = transform

    def __len__(self):
        return len(self.target_image_paths)
    
    def __getitem__(self, index):
        try:
            image_path = self.input_image_paths[index]
            mask_path = self.target_image_paths[index]

            # å°‡ "\" æ›æˆ "/"ï¼Œä»¥é¿å…è®€å–å¤±æ•—çš„å•é¡Œ #
            #image_path = image_path.replace("\\", "/")
            #mask_path = mask_path.replace("\\", "/")

            # å˜—è©¦è®€å–å½±åƒ #
            image = cv2.imread(image_path)
            if image is None:
                raise FileNotFoundError(f"âŒ ç„¡æ³•è®€å–å½±åƒ: {image_path}")

            # å°‡é¡è‰²æ ¼å¼æ”¹ç‚º RGB ä¸¦å°‡å½±åƒå¤§å°èª¿æ•´ç‚º 256x256 #
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = cv2.resize(image, self.image_size, interpolation = cv2.INTER_NEAREST)

            # å˜—è©¦è®€å– Mask #
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            if mask is None:
                raise FileNotFoundError(f"âŒ ç„¡æ³•è®€å– Mask: {mask_path}")
            
            # èª¿æ•´ Mask å¤§å°ç‚º 256x256 #
            mask = cv2.resize(mask, self.image_size, interpolation = cv2.INTER_LINEAR)

            # è½‰æ› Mask (1, 2, 3 -> 0, 1) #
            mask = np.where(mask == 1, 0, mask)
            mask = np.where(mask >= 2, 1, mask)

            # å½±åƒå¢å¼· #
            self.transform = A.Compose([
                A.HorizontalFlip(p=0.5),                      # 50% æ©Ÿç‡æ°´å¹³ç¿»è½‰
                A.RandomRotate90(p=0.5),                      # éš¨æ©Ÿæ—‹è½‰ 90 åº¦
                A.Affine(                                     # éš¨æ©Ÿå¹³ç§»ã€ç¸®æ”¾ã€æ—‹è½‰
                    scale=(0.9, 1.1), 
                    translate_percent=(0.0, 0.1), 
                    rotate=(-15, 15), p=0.5
                    ),           
                A.RandomBrightnessContrast(p=0.3),            # éš¨æ©Ÿäº®åº¦å°æ¯”
                A.GaussianBlur(p=0.2),                        # æ¨¡ç³Šå½±åƒ
                A.Normalize(mean=(0.5, 0.5, 0.5),             # Normalize for image
                            std=(0.5, 0.5, 0.5)),
                ToTensorV2()                                  # è½‰æˆ PyTorch Tensor
            ])

            if self.transform:
                augmented = self.transform(image = image, mask = mask)
                image, mask = augmented["image"], augmented["mask"]

            # è½‰æ›ç‚º Pytorch Tensor #
            if isinstance(image, np.ndarray):
                image = torch.tensor(image, dtype = torch.float32).permute(2, 0, 1) / 255.0

            if not isinstance(mask, torch.Tensor):
                mask = torch.tensor(mask, dtype = torch.long)
            else:
                mask = mask.clone().detach().long()

            return image, mask
        
        except Exception as e:
            print(f"âš ï¸ è·³éæ¨£æœ¬ (index {index}): {e}")

            return self.__getitem__((index + 1) % len(self))
        
if __name__ == "__main__":
    # è¨­å®šè³‡æ–™é›†è·¯å¾‘ #
    DATASET_PATH = "dataset/oxford-iiit-pet/"
    IMAGE_PATH = os.path.join(DATASET_PATH, "images")
    MASK_PATH = os.path.join(DATASET_PATH, "annotations/trimaps")

    # è®€å–æ‰€æœ‰ images å’Œ annotations #
    image_files = sorted(glob(os.path.join(IMAGE_PATH, "*.jpg"), recursive=True))
    mask_files = sorted(glob(os.path.join(MASK_PATH, "*.png"), recursive=True))

    # ç¢ºä¿ images å’Œ annotations æ•¸é‡ä¸€è‡´ #
    assert len(image_files) == len(mask_files), "å½±åƒèˆ‡æ¨™è¨»æ•¸é‡ä¸åŒ¹é…ï¼"

    # éš¨æ©ŸåŠƒåˆ†è³‡æ–™é›† (80% è¨“ç·´ã€10% é©—è­‰ã€10% æ¸¬è©¦) #
    train_img, temp_img, train_mask, temp_mask = train_test_split(image_files, mask_files, test_size=0.2, random_state=42)
    val_img, test_img, val_mask, test_mask = train_test_split(temp_img, temp_mask, test_size=0.5, random_state=42)

    # å»ºç«‹ PyTorch Dataset
    train_dataset = OxfordPets(train_img, train_mask, transform=None)
    val_dataset = OxfordPets(val_img, val_mask, transform=None)
    test_dataset = OxfordPets(test_img, test_mask, transform=None)

    # å»ºç«‹ DataLoader
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

    # æ¸¬è©¦è¨“ç·´é›†ã€é©—è­‰é›†ã€æ¸¬è©¦é›†çš„å½±åƒæ•¸é‡ #
    print(f"ğŸ”¢ è¨“ç·´è³‡æ–™æ•¸é‡: {len(train_dataset)}")
    print(f"ğŸ” é©—è­‰è³‡æ–™æ•¸é‡: {len(val_dataset)}")
    print(f"ğŸ§ª æ¸¬è©¦è³‡æ–™æ•¸é‡: {len(test_dataset)}\n")

    # æŸ¥çœ‹å„å€‹ DataLoader çš„æ‰¹æ¬¡æ•¸é‡ #
    print(f"ğŸ“¦ è¨“ç·´æ‰¹æ¬¡æ•¸é‡: {len(train_loader)}")
    print(f"ğŸ“¦ é©—è­‰æ‰¹æ¬¡æ•¸é‡: {len(val_loader)}")
    print(f"ğŸ“¦ æ¸¬è©¦æ‰¹æ¬¡æ•¸é‡: {len(test_loader)}\n")

    # æ¸¬è©¦è®€å–è¨“ç·´é›†çš„ä¸€å€‹ batch #
    sample_images, sample_masks = next(iter(train_loader))

    print(f"å½±åƒæ‰¹æ¬¡å¤§å°: {sample_images.shape}")
    print(f"æ¨™è¨»æ‰¹æ¬¡å¤§å°: {sample_masks.shape}\n")
    
    image_np = sample_images[0].permute(1, 2, 0).numpy()  # [C, H, W] â†’ [H, W, C]
    mask_np = sample_masks[0].squeeze(0).numpy()  # [1, H, W] â†’ [H, W]

    # é¡¯ç¤ºå½±åƒèˆ‡ Mask #
    utils.plot_batch_sample(image_np, mask_np)